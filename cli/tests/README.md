# Arena CLI Testing Guide

## ğŸ¯ Testing Strategy

Arena uses a comprehensive 3-tier testing approach:

1. **Unit Tests** - Test individual functions and modules in isolation
2. **Integration Tests** - Test how components work together
3. **E2E Tests** - Test complete workflows from CLI to output

## ğŸ“ Test Structure

```
tests/
â”œâ”€â”€ setup.ts                 # Global test configuration
â”œâ”€â”€ unit/                    # Unit tests
â”‚   â”œâ”€â”€ validation.test.ts
â”‚   â”œâ”€â”€ config.test.ts
â”‚   â””â”€â”€ ...
â”œâ”€â”€ integration/             # Integration tests
â”‚   â”œâ”€â”€ process-command.test.ts
â”‚   â”œâ”€â”€ analyze-command.test.ts
â”‚   â””â”€â”€ ...
â”œâ”€â”€ e2e/                     # End-to-end tests
â”‚   â””â”€â”€ full-workflow.test.ts
â”œâ”€â”€ fixtures/                # Test data
â”‚   â”œâ”€â”€ test-config.json
â”‚   â”œâ”€â”€ test-analysis.json
â”‚   â””â”€â”€ test-video.mp4
â””â”€â”€ mocks/                   # Mock implementations
    â””â”€â”€ python-bridge.mock.ts
```

## ğŸš€ Running Tests

### Run all tests
```bash
npm test
```

### Run tests in watch mode
```bash
npm run test:watch
```

### Run with coverage
```bash
npm run test:coverage
```

### Run specific test file
```bash
npm test validation.test.ts
```

### Run tests with UI
```bash
npm run test:ui
```

## ğŸ“Š Coverage Goals

We aim for **70%+ coverage** across all metrics:
- Lines: 70%
- Functions: 70%
- Branches: 70%
- Statements: 70%

## âœï¸ Writing Tests

### Unit Test Example

```typescript
import { describe, it, expect } from 'vitest';
import { myFunction } from '../src/module.js';

describe('MyModule', () => {
  it('should do something', () => {
    const result = myFunction('input');
    expect(result).toBe('expected output');
  });
});
```

### Integration Test Example

```typescript
import { describe, it, expect, beforeEach, vi } from 'vitest';
import { MyCommand } from '../src/commands/my-command.js';
import { MockPythonBridge } from './mocks/python-bridge.mock.js';

vi.mock('../src/bridge/python-bridge.js', () => ({
  PythonBridge: MockPythonBridge,
}));

describe('MyCommand Integration', () => {
  it('should execute command', async () => {
    await expect(MyCommand('arg')).resolves.not.toThrow();
  });
});
```

## ğŸ§ª Test Fixtures

Test fixtures are located in `tests/fixtures/`:
- `test-config.json` - Sample configuration
- `test-analysis.json` - Sample analysis output
- `test-video.mp4` - Small test video (not committed)

## ğŸ­ Mocking

We mock the Python bridge in tests to:
- Speed up tests (no actual Python execution)
- Make tests deterministic
- Avoid requiring OpenAI API key
- Test error scenarios

## â­ï¸ Skipping Tests

Use `.skip` for tests that require external resources:

```typescript
it.skip('should process real video', async () => {
  // This test requires a real video file and API key
});
```

## ğŸ› Debugging Tests

```bash
# Run tests with verbose output
npm test -- --reporter=verbose

# Run single test file
npm test validation.test.ts

# Debug in VS Code
# Add breakpoint and use "JavaScript Debug Terminal"
```

## ğŸ“ˆ CI/CD Integration

Tests run automatically on:
- Every commit (via pre-commit hook)
- Every push (via GitHub Actions)
- Before publishing (via prepublishOnly)

## ğŸ”§ Troubleshooting

### Tests failing locally but passing in CI
- Check Node.js version (requires 18+)
- Clear node_modules and reinstall
- Check for environment-specific issues

### Coverage below threshold
- Add tests for uncovered files
- Check coverage report: `open coverage/index.html`

### Mock not working
- Ensure mock is imported before the module being tested
- Use `vi.mock()` at the top of test file

## ğŸ“š Resources

- [Vitest Documentation](https://vitest.dev)
- [Testing Best Practices](https://github.com/goldbergyoni/javascript-testing-best-practices)
- [Mocking Guide](https://vitest.dev/guide/mocking.html)
